<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriately as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DPLM-2">
  <meta property="og:title" content="DPLM-2" />
  <meta property="og:description" content="DPLM-2: A Multimodal Diffusion Protein Language Model" />
  <meta property="og:url" content="https://bytedance.github.io/dplm/dplm-2.html" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimensions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="DPLM-2">
  <meta name="twitter:description" content="DPLM-2: A Multimodal Diffusion Protein Language Model">
  <!-- Path to banner image, should be in the path listed below. Optimal dimensions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Protein Language Model; Diffusion Model; Mulitimodal Protein Foundation Model">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>DPLM-2</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/cryostar.png"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script src="https://fred-wang.github.io/TeXZilla/TeXZilla-min.js"></script>
  <script src="https://fred-wang.github.io/TeXZilla/examples/customElement.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
                DPLM-2: A Multimodal Diffusion Protein Language Model
            </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                Xinyou Wang,</span>
              <span class="author-block">
                Zaixiang Zheng<sup>*</sup>,</span>
              <span class="author-block">
                Fei Ye,</span>
              <span class="author-block">
                Dongyu Xue,</span>
              <span class="author-block">
                Shujian Huang, and </span>
              <span class="author-block">
                Quanquan Gu<sup>#</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                ByteDance Research, Nanjing University
              </span>
              <span class="eql-cntrb"><small><br>
                  <sup>*</sup>Project Lead
                  &nbsp;&nbsp;&nbsp;
                  <sup>#</sup>Corresponding Author
                </small>
              </span>
            </div>

            <div class="has-text-grey">
              wangxinyou@smail.nju.edu.cn, {zhengzaixiang,quanquan.gu}@bytedance.com
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2410.13782" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Supplementary PDF link -->
                <!-- <span class="link-block">
                  <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Supplementary</span>
                  </a>
                </span> -->

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/bytedance/dplm" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code and models will be released</span>
                  </a>
                </span>

                <!-- Documentation link -->
                <!-- <span class="link-block">
                  <a href="https://byte-research.gitbook.io/cryostar" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-book"></i>
                    </span>
                    <span>User Guide</span>
                  </a>
                </span> -->

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span> -->
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <!-- <img src="https://lf3-nlp-opensource.bytetos.com/obj/nlp-opensource/cryofm/images/intro.jpg" alt="MAIN_FIGURE" /> -->
        <!-- <video poster="" id="video" autoplay controls muted loop height="100%">
          <source src="https://lf3-nlp-opensource.bytetos.com/obj/nlp-opensource/cryofm/videos/cryofm.mp4" type="video/mp4">
        </video> -->
        <img class="center-image-carousel blend-img-background" src="res/dplm-2/main.png">
        
        <h2 class="subtitle has-text-justified">
            DPLM-2 is a brand-new multimodal protein foundation model that extends <a href="https://github.com/bytedance/dplm">Diffusion Protein Language Model (DPLM, ICML'24)</a> to model, understand, generate and reason over both protein structures and sequences. 
        </h2>
      </div>
    </div>
  </section>

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
                Proteins are essential macromolecules defined by their amino acid sequences, which determine their three-dimensional structures and, consequently, their functions in all living organisms. Therefore, generative protein modeling necessitates a multimodal approach to simultaneously model, understand, and generate both sequences and structures. However, existing methods typically use separate models for each modality, limiting their ability to capture the intricate relationships between sequence and structure. This results in suboptimal performance in tasks that requires joint understanding and generation of both modalities.

            <p></p>
                In this paper, we introduce DPLM-2, a multimodal protein foundation model that extends discrete diffusion protein language model (DPLM) to accommodate both sequences and structures.
                To enable structural learning with the language model, 3D coordinates are converted to discrete tokens using a lookup-free quantization-based tokenizer.
                By training on both experimental and high-quality synthetic structures, DPLM-2 learns the joint distribution of sequence and structure, as well as their marginals and conditionals.
                We also implement an efficient warm-up strategy to exploit the connection between large-scale evolutionary data and structural inductive biases from pre-trained sequence-based protein language models.
                Empirical evaluation shows that DPLM-2 can simultaneously generate highly compatible amino acid sequences and their corresponding 3D structures eliminating the need for a two-stage generation approach.
                Moreover, DPLM-2 demonstrates competitive performance in various conditional generation tasks, including folding, inverse folding, and scaffolding with multimodal motif inputs, as well as providing structure-aware representations for predictive tasks.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->

  <!-- Image carousel
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container" style="width: 960px; max-width: 100%">
        <h2 class="title has-text-centered">Results on 4 downstream tasks</h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
              <img class="center-image-carousel blend-img-background" src="https://lf3-nlp-opensource.bytetos.com/obj/nlp-opensource/cryofm/images/task1.jpg">
          </div>

          <div class="item">
              <img class="center-image-carousel blend-img-background" src="https://lf3-nlp-opensource.bytetos.com/obj/nlp-opensource/cryofm/images/task2.jpg">
          </div>

          <div class="item">
              <img class="center-image-carousel blend-img-background" src="https://lf3-nlp-opensource.bytetos.com/obj/nlp-opensource/cryofm/images/task3.jpg">
          </div>

          <div class="item">
              <img class="center-image-carousel blend-img-background" src="https://lf3-nlp-opensource.bytetos.com/obj/nlp-opensource/cryofm/images/task4.jpg">
          </div>

        </div>
      </div>
    </div>
  </section> -->
  <!-- End image carousel -->

  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @article{wang2024dplm2,
          title={DPLM-2: A Multimodal Diffusion Protein Language Model}, 
          author={Xinyou Wang and Zaixiang Zheng and Fei Ye and Dongyu Xue and Shujian Huang and Quanquan Gu},
          year={2024},
          eprint={2410.13782},
          archivePrefix={arXiv},
          primaryClass={cs.LG},
          url={https://arxiv.org/abs/2410.13782}, 
        }
      </code></pre>
    </div>
  </section>
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the of this website, we just ask that you link back to this page in the footer.
              <br> This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>
